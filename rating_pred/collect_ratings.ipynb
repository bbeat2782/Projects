{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import sqlite3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraped data from : https://www.metacritic.com/browse/movies/score/metascore/all/filtered?page=0\n",
    "\n",
    "Using the information from : https://www.makeuseof.com/tag/best-movie-ratings-sites/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://www.metacritic.com/'\n",
    "sqldb_path = 'data/rating_database.db'\n",
    "headers = {\n",
    "    'Accept-Encoding': 'gzip, deflate, sdch',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Connection': 'keep-alive',\n",
    "}\n",
    "\n",
    "def insert_into_sql(statement, db_path = sqldb_path):\n",
    "    \"\"\"\n",
    "    Insert or update sql database based on the statement parameter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    statement : str\n",
    "        The statement to execute\n",
    "    db_path : str\n",
    "        Path to sqlite database that you want to execute the statements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        sqliteConnection = sqlite3.connect(db_path)\n",
    "        cursor = sqliteConnection.cursor()\n",
    "        cursor.execute(statement)\n",
    "        sqliteConnection.commit()\n",
    "        cursor.close()\n",
    "    except sqlite3.Error as error:\n",
    "        print(\"Error while connecting to sqlite\", error)\n",
    "\n",
    "\n",
    "def fetch_from_sql(statement, db_path = sqldb_path):\n",
    "    \"\"\"\n",
    "    Fetch from sql database based on the statement parameter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    statement : str\n",
    "        The statement to execute\n",
    "    db_path : str\n",
    "        Path to sql database that you want to execute the statements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fetch_items : list\n",
    "        A list of elements that match the statement from sql database\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        sqliteConnection = sqlite3.connect(db_path)\n",
    "        cursor = sqliteConnection.cursor()\n",
    "        cursor.execute(statement)\n",
    "        fetch_items = cursor.fetchall()\n",
    "        cursor.close()\n",
    "\n",
    "        return fetch_items\n",
    "    except sqlite3.Error as error:\n",
    "        print(\"Error while connecting to sqlite\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genres(movie_soup):\n",
    "    \"\"\"\n",
    "    Get genres from the given movie_soup\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    movie_soup : BeautifulSoup obj\n",
    "        Parsed html for the given movie\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    genre1 : str or None\n",
    "        First listed genre of the movie. None if not listed\n",
    "    genre2 : str or None\n",
    "        Second listed genre of the movie. None if not listed\n",
    "    genre3 : str or None\n",
    "        Third listed genre of the movie. None if not listed\n",
    "    \"\"\"\n",
    "    \n",
    "    genre1, genre2, genre3 = None, None, None\n",
    "    genres = [s.strip() for s in movie_soup.find('div', {'class': 'genres'})\n",
    "                                           .text.split(':')[1].split(',')]\n",
    "\n",
    "    try:\n",
    "        genre1 = genres[0].strip()\n",
    "        try:\n",
    "            genre2 = genres[1].strip()\n",
    "            try:\n",
    "                genre3 = genres[2].strip()\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return genre1, genre2, genre3\n",
    "\n",
    "\n",
    "def get_movie_info(url, headers=headers):\n",
    "    \"\"\"\n",
    "    Get movie information and insert into a sql database. The information is\n",
    "    movie title, year, critic_score, user_score, summary, rating, runtime, \n",
    "    genres, and positive, mixed, negative critics & users reviews count.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        url of the movie from metacritic website\n",
    "    headers : dict\n",
    "        Browser information to pass in when calling requests\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    movie_id : str\n",
    "        Hash id generated by passing a movie title to python hash function\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating BeautifulSoup object with the given url\n",
    "    movie_res = requests.get(url, headers=headers).text\n",
    "    movie_soup = BeautifulSoup(movie_res, 'html.parser')\n",
    "\n",
    "    # Retrieving critic and user scores\n",
    "    scores = movie_soup.find_all('div', {'class': 'score fl'})\n",
    "    critic_score = scores[0].text.strip()\n",
    "    user_score = scores[1].text.strip()\n",
    "    # some movies don't have user reviews and have tbd instead of floating point\n",
    "    if user_score == 'tbd':\n",
    "        return None\n",
    "    \n",
    "    # Retrieving title, year, and movie_id\n",
    "    title_year = movie_soup.find('div', {'class': 'product_page_title'}).text.strip().split('\\n')\n",
    "    title = title_year[0]\n",
    "    year = title_year[1]\n",
    "    movie_id = hash(title)\n",
    "\n",
    "    # Checking whether I already collected the movie info or not\n",
    "    # If yes, returns None\n",
    "    check_statement = f'SELECT movie_id FROM Movie WHERE movie_id = {movie_id}'\n",
    "    if len(fetch_from_sql(check_statement)) > 0:\n",
    "        return None\n",
    "\n",
    "    # Retrieving summary\n",
    "    summary = movie_soup.find('div', {'class': 'summary_deck'}).text.replace('\"', '')\n",
    "    if summary.startswith('\\nSummary:'):\n",
    "        summary = summary[9:].strip()\n",
    "    if summary.endswith('… Expand'):\n",
    "        summary = summary[:-8]\n",
    "\n",
    "    # Retrieving rating (PG, PG-13, R, etc)\n",
    "    try:\n",
    "        rating = movie_soup.find('div', {'class': 'rating'}).text.split(':')[1].strip()\n",
    "    except:\n",
    "        # Some films (in the early history or independent films) are not rated\n",
    "        rating = 'Not Rated'\n",
    "\n",
    "    # Retrieving runtime\n",
    "    try:\n",
    "        runtime = movie_soup.find('div', {'class': 'runtime'}).text.split(':')[1].strip()\n",
    "        if runtime.endswith(' min'):\n",
    "            runtime = runtime[:-4]\n",
    "    except:\n",
    "        # Assigning -1 for some films that don't have runtime specified\n",
    "        runtime = -1\n",
    "\n",
    "    # Retrieving genres\n",
    "    g1, g2, g3 = get_genres(movie_soup)\n",
    "\n",
    "    # Retrieving critics' and users' positive, mixed, and negative review counts\n",
    "    pos = [d.text.split(':')[1].strip().replace(',', '') \n",
    "           for d in movie_soup.find_all('div', {'class': 'chart positive'})]\n",
    "    mix = [d.text.split(':')[1].strip().replace(',', '') \n",
    "           for d in movie_soup.find_all('div', {'class': 'chart mixed'})]\n",
    "    neg = [d.text.split(':')[1].strip().replace(',', '') \n",
    "           for d in movie_soup.find_all('div', {'class': 'chart negative'})]\n",
    "    num_critic_pos, num_critic_mix, num_critic_neg = pos[0], mix[0], neg[0]\n",
    "    num_user_pos, num_user_mix, num_user_neg = pos[1], mix[1], neg[1]\n",
    "\n",
    "    # Inserting all the information into a sqlite database\n",
    "    insert_statement = f'INSERT INTO Movie (movie_id, movie_title, movie_year, movie_summary, \\\n",
    "        movie_critic_rating, movie_user_rating, movie_runtime, movie_genre, movie_subgenre, \\\n",
    "        movie_sub2genre, movie_rating, num_critic_pos, num_critic_mix, num_critic_neg, \\\n",
    "        num_user_pos, num_user_mix, num_user_neg) VALUES (\"{movie_id}\", \"{title}\", {year}, \"{summary}\", \\\n",
    "        {critic_score}, {user_score}, {runtime}, \"{g1}\", \"{g2}\", \"{g3}\", \"{rating}\", {num_critic_pos},\\\n",
    "        {num_critic_mix}, {num_critic_neg}, {num_user_pos}, {num_user_mix}, {num_user_neg})'\n",
    "    insert_into_sql(insert_statement)\n",
    "\n",
    "    return movie_id\n",
    "\n",
    "\n",
    "def get_reviews(url, movie_id, critic=True, first=True, headers=headers):\n",
    "    \"\"\"\n",
    "    Get movie reviews and insert into a sql database. It can retrieve reviews\n",
    "    from both critics and users by setting the critic parameter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        url of the movie reviews from metacritic website\n",
    "    movie_id : str\n",
    "        hash value of movie title after passed into python hash function\n",
    "    critic : bool\n",
    "        True if given url is for reviews from critics. False if otherwise\n",
    "    first : bool\n",
    "        True if it's the first time retrieving reviews from this movie. False if \n",
    "        this function is called recursively\n",
    "    headers : dict\n",
    "        Browser information to pass in when calling requests\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating BeautifulSoup object with the given url\n",
    "    res = requests.get(url, headers=headers).text\n",
    "    soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "    # Retrieve names, dates, ratings of reviews\n",
    "    names = [s.text.strip() for s in soup.find_all('span', {'class': 'author'})]\n",
    "    dates = [s.text.strip() for s in soup.find_all('span', {'class': 'date'})]\n",
    "    ratings = [s.text.strip() for s in soup.find_all('div', {'class': 'left fl'})]\n",
    "\n",
    "    # Some early film reviews don't have dates --> Fill in with 'None'\n",
    "    if len(names) != len(dates):\n",
    "        dates = ['None'] * len(names)\n",
    "\n",
    "    # Different approaches for retrieving reviews for critics/users\n",
    "    if critic:\n",
    "        reviews = [s.text.strip().replace('\"', '') for s in soup.find_all('a', {'class': 'no_hover'})]\n",
    "    else:\n",
    "        tmp_reviews = [s for s in soup.find_all('div', {'class': 'review_body'})]\n",
    "        reviews = [r.find('span', {'class': 'blurb blurb_expanded'}).text.strip().replace('\"', '') \n",
    "                   if r.find('span', {'class': 'blurb blurb_expanded'}) \n",
    "                   else r.text.strip().replace('\"', '') for r in tmp_reviews]\n",
    "\n",
    "    # Different insert_statement for Critics/Users tables\n",
    "    tb, sub = 'Users', 'user'\n",
    "    if critic: \n",
    "        tb, sub = 'Critics', 'critic'\n",
    "    insert_statement = f'INSERT INTO {tb} (movie_id, {sub}_name, {sub}_review, {sub}_date, {sub}_rating) VALUES'\n",
    "\n",
    "    # Looping through collected information to create one insert statement\n",
    "    # for multiple rows\n",
    "    for n,d,ra,re in zip(names, dates, ratings, reviews):\n",
    "        addition = f' (\"{movie_id}\",  \"{n}\", \"{re}\", \"{d}\", {ra}),'\n",
    "        insert_statement += addition\n",
    "    if len(names) > 0:\n",
    "        insert_into_sql(insert_statement[:-1])\n",
    "\n",
    "    # Calling get_reviews() recursively when there is more than one page of reviews\n",
    "    #   Only using it when retrieving reviews for users since critics review page is\n",
    "    #   almost always in a single page\n",
    "    if first and not critic:\n",
    "        try:\n",
    "            last_page = soup.find('li', {'class': 'page last_page'}).text\n",
    "            if last_page.startswith('…'):\n",
    "                last_page = last_page[1:]\n",
    "            \n",
    "            for i in range(int(last_page)):\n",
    "                next_review_url = url + '?page=' + str(i)\n",
    "                get_reviews(next_review_url, movie_id, critic=False, first=False)\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(156):\n",
    "    url = f'https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page={i}'\n",
    "    res = requests.get(url, headers=headers).text\n",
    "    soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "    # Looping through all movies displayed on a page\n",
    "    for movie in soup.find_all('td', {'class': 'clamp-summary-wrap'}):\n",
    "        try:\n",
    "            movie_endpoint = movie.find_all('a')[1]['href']\n",
    "            critic_endpoint = movie_endpoint + '/critic-reviews'\n",
    "            user_endpoint = movie_endpoint + '/user-reviews'\n",
    "            movie_id = get_movie_info(base_url+movie_endpoint)\n",
    "            \n",
    "            # Get reviews when get_movie_info() does not return None\n",
    "            if movie_id:\n",
    "                get_reviews(base_url+critic_endpoint, movie_id, critic=True)\n",
    "                try:\n",
    "                    get_reviews(base_url+user_endpoint, movie_id, critic=False)\n",
    "                except:\n",
    "                    pass\n",
    "        except:\n",
    "            print(f\"Didn't work: {movie_endpoint}\")\n",
    "\n",
    "        time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rating_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
